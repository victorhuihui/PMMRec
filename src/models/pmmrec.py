# coding: utf-8
#
# user-graph need to be generated by the following script
# tools/generate-u-u-matrix.py
import os
import numpy as np
import scipy.sparse as sp
import torch
import torch.nn as nn
import torch.nn.functional as F
import random
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.utils import remove_self_loops, add_self_loops, degree
import torch_geometric
from collections import Counter
from scipy.sparse import csr_matrix

from common.abstract_recommender import GeneralRecommender
from common.loss import BPRLoss, EmbLoss
from common.init import xavier_uniform_initialization


class PMMRec(GeneralRecommender):
    def __init__(self, config, dataset):
        super(PMMRec, self).__init__(config, dataset)

        num_user = self.n_users
        num_item = self.n_items
        batch_size = config['train_batch_size']  # not used
        dim_x = config['embedding_size']
        self.feat_embed_dim = config['feat_embed_dim']
        self.n_layers = config['n_mm_layers']
        self.knn_k = config['knn_k']
        self.mm_image_weight = config['mm_image_weight']

        self.batch_size = batch_size
        self.num_user = num_user
        self.num_item = num_item
        self.k = 40
        self.aggr_mode = 'add'
        self.dataset = dataset
        self.dropout = config['dropout']
        # self.construction = 'weighted_max'
        self.reg_weight = config['reg_weight']
        self.align_weight = config['align_weight']
        # self.mask_weight_g = config['mask_weight_g']
        self.mask_weight_f = config['mask_weight_f']
        self.temp = config['temp']
        self.drop_rate = 0.1
        self.v_rep = None
        self.t_rep = None
        self.v_preference = None
        self.t_preference = None
        self.id_preference = None
        self.dim_latent = 64
        self.dim_feat = 128
        self.mm_adj = None

        self.mlp = nn.Linear(2*dim_x, 2*dim_x)

        dataset_path = os.path.abspath(config['data_path'] + config['dataset'])
        self.user_graph_dict = np.load(os.path.join(dataset_path, config['user_graph_dict_file']),
                                       allow_pickle=True).item()
        self.uu_adj = self.build_user_sparse_adj(self.user_graph_dict, self.num_user, device=self.device)

        mm_adj_file = os.path.join(dataset_path, 'mm_adj_{}.pt'.format(self.knn_k))

        if self.v_feat is not None:
            self.image_embedding = nn.Embedding.from_pretrained(self.v_feat, freeze=False)
            self.image_trs = nn.Linear(self.v_feat.shape[1], self.feat_embed_dim)
        if self.t_feat is not None:
            self.text_embedding = nn.Embedding.from_pretrained(self.t_feat, freeze=False)
            self.text_trs = nn.Linear(self.t_feat.shape[1], self.feat_embed_dim)

        if os.path.exists(mm_adj_file):
            self.mm_adj = torch.load(mm_adj_file)
        else:
            if self.v_feat is not None:
                indices, image_adj = self.get_knn_adj_mat(self.image_embedding.weight.detach())
                self.mm_adj = image_adj
            if self.t_feat is not None:
                indices, text_adj = self.get_knn_adj_mat(self.text_embedding.weight.detach())
                self.mm_adj = text_adj
            if self.v_feat is not None and self.t_feat is not None:
                self.mm_adj = self.mm_image_weight * image_adj + (1.0 - self.mm_image_weight) * text_adj
                del text_adj
                del image_adj
            torch.save(self.mm_adj, mm_adj_file)

        # packing interaction in training into edge_index
        train_interactions = dataset.inter_matrix(form='coo').astype(np.float32)
        edge_index = self.pack_edge_index(train_interactions)
        self.edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous().to(self.device)
        self.edge_index = torch.cat((self.edge_index, self.edge_index[[1, 0]]), dim=1)

        self.inter_adj = self.build_torch_sparse_adj(self.edge_index, self.num_user + self.num_item, device=self.device)

        # pdb.set_trace()
        self.weight_u = nn.Parameter(nn.init.xavier_normal_(
            torch.tensor(np.random.randn(self.num_user, 2, 1), dtype=torch.float32, requires_grad=True)))
        self.weight_u.data = F.softmax(self.weight_u, dim=1)

        self.weight_i = nn.Parameter(nn.init.xavier_normal_(
            torch.tensor(np.random.randn(self.num_item, 2, 1), dtype=torch.float32, requires_grad=True)))
        self.weight_i.data = F.softmax(self.weight_i, dim=1)

        self.item_index = torch.zeros([self.num_item], dtype=torch.long)
        index = []
        for i in range(self.num_item):
            self.item_index[i] = i
            index.append(i)
        self.drop_percent = self.drop_rate
        self.single_percent = 1
        self.double_percent = 0

        drop_item = torch.tensor(
            np.random.choice(self.item_index, int(self.num_item * self.drop_percent), replace=False))
        drop_item_single = drop_item[:int(self.single_percent * len(drop_item))]

        self.dropv_node_idx_single = drop_item_single[:int(len(drop_item_single) * 1 / 3)]
        self.dropt_node_idx_single = drop_item_single[int(len(drop_item_single) * 2 / 3):]

        self.dropv_node_idx = self.dropv_node_idx_single
        self.dropt_node_idx = self.dropt_node_idx_single

        mask_cnt = torch.zeros(self.num_item, dtype=int).tolist()
        for edge in edge_index:
            mask_cnt[edge[1] - self.num_user] += 1
        mask_dropv = []
        mask_dropt = []
        for idx, num in enumerate(mask_cnt):
            temp_false = [False] * num
            temp_true = [True] * num
            mask_dropv.extend(temp_false) if idx in self.dropv_node_idx else mask_dropv.extend(temp_true)
            mask_dropt.extend(temp_false) if idx in self.dropt_node_idx else mask_dropt.extend(temp_true)

        edge_index = edge_index[np.lexsort(edge_index.T[1, None])]
        edge_index_dropv = edge_index[mask_dropv]
        edge_index_dropt = edge_index[mask_dropt]

        self.edge_index_dropv = torch.tensor(edge_index_dropv).t().contiguous().to(self.device)
        self.edge_index_dropt = torch.tensor(edge_index_dropt).t().contiguous().to(self.device)

        self.edge_index_dropv = torch.cat((self.edge_index_dropv, self.edge_index_dropv[[1, 0]]), dim=1)
        self.edge_index_dropt = torch.cat((self.edge_index_dropt, self.edge_index_dropt[[1, 0]]), dim=1)

        self.MLP_user = nn.Linear(self.dim_latent * 2, self.dim_latent)

        if self.v_feat is not None:
            self.v_gcn = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode, dim_latent=64,
                             device=self.device, features=self.v_feat)
            self.v_gcn_n1 = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode, dim_latent=64,
                             device=self.device, features=self.v_feat)
            self.v_gcn_n2 = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode, dim_latent=64,
                                device=self.device, features=self.v_feat)
        if self.t_feat is not None:
            self.t_gcn = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode, dim_latent=64,
                             device=self.device, features=self.t_feat)
            self.t_gcn_n1 = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode, dim_latent=64,
                             device=self.device, features=self.t_feat)
            self.t_gcn_n2 = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode, dim_latent=64,
                                device=self.device, features=self.t_feat)

        self.id_feat = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(self.n_items, self.dim_latent), dtype=torch.float32,
                                                requires_grad=True), gain=1).to(self.device))
        self.id_gcn = GCN(self.dataset, batch_size, num_user, num_item, dim_x, self.aggr_mode,
                          dim_latent=64, device=self.device, features=self.id_feat)


        self.result_embed = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(num_user + num_item, dim_x)))).to(self.device)

        self.result_embed_guide = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(num_user + num_item, dim_x)))).to(self.device)
        self.result_embed_v = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(num_user + num_item, dim_x)))).to(self.device)
        self.result_embed_t = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(num_user + num_item, dim_x)))).to(self.device)
        self.result_embed_n1 = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(num_user + num_item, dim_x)))).to(self.device)
        self.result_embed_n2 = nn.Parameter(
            nn.init.xavier_normal_(torch.tensor(np.random.randn(num_user + num_item, dim_x)))).to(self.device)

        # 增加初始MoE
        self.start_moe_user = Align_MoE(config)
        self.start_moe_item = Align_MoE(config)

    def get_knn_adj_mat(self, mm_embeddings):
        context_norm = mm_embeddings.div(torch.norm(mm_embeddings, p=2, dim=-1, keepdim=True))
        sim = torch.mm(context_norm, context_norm.transpose(1, 0))
        _, knn_ind = torch.topk(sim, self.knn_k, dim=-1)
        adj_size = sim.size()
        del sim
        # construct sparse adj
        indices0 = torch.arange(knn_ind.shape[0]).to(self.device)
        indices0 = torch.unsqueeze(indices0, 1)
        indices0 = indices0.expand(-1, self.knn_k)
        indices = torch.stack((torch.flatten(indices0), torch.flatten(knn_ind)), 0)
        # norm
        return indices, self.compute_normalized_laplacian(indices, adj_size)

    def compute_normalized_laplacian(self, indices, adj_size):
        adj = torch.sparse.FloatTensor(indices, torch.ones_like(indices[0]), adj_size)
        row_sum = 1e-7 + torch.sparse.sum(adj, -1).to_dense()
        r_inv_sqrt = torch.pow(row_sum, -0.5)
        rows_inv_sqrt = r_inv_sqrt[indices[0]]
        cols_inv_sqrt = r_inv_sqrt[indices[1]]
        values = rows_inv_sqrt * cols_inv_sqrt
        return torch.sparse.FloatTensor(indices, values, adj_size)

    def pre_epoch_processing(self):
        self.epoch_user_graph, self.user_weight_matrix = self.topk_sample(self.k)
        self.user_weight_matrix = self.user_weight_matrix.to(self.device)

    def pack_edge_index(self, inter_mat):
        rows = inter_mat.row
        cols = inter_mat.col + self.n_users
        # ndarray([598918, 2]) for ml-imdb
        return np.column_stack((rows, cols))

    def InfoNCE(self, view1, view2, temp):
        view1, view2 = F.normalize(view1, dim=1), F.normalize(view2, dim=1)
        pos_score = (view1 * view2).sum(dim=-1)
        pos_score = torch.exp(pos_score / temp)
        ttl_score = torch.matmul(view1, view2.transpose(0, 1))
        ttl_score = torch.exp(ttl_score / temp).sum(dim=1)
        cl_loss = -torch.log(pos_score / ttl_score)
        return torch.mean(cl_loss)

    def forward(self, interaction):
        user_nodes, pos_item_nodes, neg_item_nodes = interaction[0], interaction[1], interaction[2]
        pos_item_nodes += self.n_users
        neg_item_nodes += self.n_users

        # GCN for id, v, t modalities
        self.v_rep, self.v_preference = self.v_gcn(self.edge_index_dropv, self.edge_index, self.v_feat)
        self.t_rep, self.t_preference = self.t_gcn(self.edge_index_dropt, self.edge_index, self.t_feat)
        self.id_rep, self.id_preference = self.id_gcn(self.edge_index_dropt, self.edge_index, self.id_feat)

        id_user_emb = self.id_rep[:self.num_user]
        t_user_emb = self.t_rep[:self.num_user]
        v_user_emb = self.v_rep[:self.num_user]

        id_item_emb = self.id_rep[self.num_user:]
        t_item_emb = self.t_rep[self.num_user:]
        v_item_emb = self.v_rep[self.num_user:]

        id_user_emb = self.lightgcn_user_propagate_sparse(id_user_emb, self.uu_adj) + id_user_emb
        t_user_emb = self.lightgcn_user_propagate_sparse(t_user_emb, self.uu_adj) + t_user_emb
        v_user_emb = self.lightgcn_user_propagate_sparse(v_user_emb, self.uu_adj) + v_user_emb

        h_id = self.buildItemGraph(id_item_emb)
        h_t = self.buildItemGraph(t_item_emb)
        h_v = self.buildItemGraph(v_item_emb)

        id_item_emb = id_item_emb + h_id
        t_item_emb = t_item_emb + h_t
        v_item_emb = v_item_emb + h_v

        ### add MoE ###
        # align_info = self.start_moe_user(torch.cat([id_user_emb, t_user_emb, v_user_emb], dim=-1))
        # id_user_emb += align_info[0]
        # t_user_emb += align_info[1]
        # v_user_emb += align_info[2]

        align_info = self.start_moe_item(torch.cat([id_item_emb, t_item_emb, v_item_emb], dim=-1))
        id_item_emb += align_info[0]
        t_item_emb += align_info[1]
        v_item_emb += align_info[2]

        result_user_id = torch.cat((id_user_emb, id_item_emb), dim=0)
        result_user_t = torch.cat((t_user_emb, t_item_emb), dim=0)
        result_user_v = torch.cat((v_user_emb, v_item_emb), dim=0)

        res_emb = torch.cat((result_user_id, result_user_t, result_user_v), dim=1)

        vir_loss = self.path_based_bpr_loss_vectorized(user_nodes, res_emb, self.inter_adj)

        self.result_embed = res_emb


        # calculate pos and neg scores
        user_tensor = self.result_embed[user_nodes]
        pos_item_tensor = self.result_embed[pos_item_nodes]
        neg_item_tensor = self.result_embed[neg_item_nodes]
        pos_scores = torch.sum(user_tensor * pos_item_tensor, dim=1)
        neg_scores = torch.sum(user_tensor * neg_item_tensor, dim=1)
        return pos_scores, neg_scores, vir_loss

    def buildItemGraph(self, h):
        for i in range(self.n_layers):
            h = torch.sparse.mm(self.mm_adj, h)
        return h

    def fit_Gaussian_dis(self):
        r_var = torch.var(self.result_embed)
        r_mean = torch.mean(self.result_embed)
        g_var = torch.var(self.result_embed_guide)
        g_mean = torch.mean(self.result_embed_guide)
        v_var = torch.var(self.result_embed_v)
        v_mean = torch.mean(self.result_embed_v)
        t_var = torch.var(self.result_embed_t)
        t_mean = torch.mean(self.result_embed_t)
        return r_var, r_mean, g_var, g_mean, v_var, v_mean, t_var, t_mean

    def calculate_loss(self, interaction):
        user = interaction[0]
        pos_scores, neg_scores, vir_loss = self.forward(interaction)
        loss_value = -torch.mean(torch.log2(torch.sigmoid(pos_scores - neg_scores)))

        # reg
        reg_embedding_loss_v = (self.v_preference[user] ** 2).mean() if self.v_preference is not None else 0.0
        reg_embedding_loss_t = (self.t_preference[user] ** 2).mean() if self.t_preference is not None else 0.0
        reg_loss = self.reg_weight * (reg_embedding_loss_v + reg_embedding_loss_t)
        reg_loss += self.reg_weight * (self.weight_u ** 2).mean()

        return reg_loss + (1-self.mask_weight_f) * loss_value + self.mask_weight_f * vir_loss

        # return loss_value + reg_loss

    def full_sort_predict(self, interaction):
        user_tensor = self.result_embed[:self.n_users]
        item_tensor = self.result_embed[self.n_users:]

        temp_user_tensor = user_tensor[interaction[0], :]
        score_matrix = torch.matmul(temp_user_tensor, item_tensor.t())
        return score_matrix

    def topk_sample(self, k):
        user_graph_index = []
        count_num = 0
        user_weight_matrix = torch.zeros(len(self.user_graph_dict), k)
        tasike = []
        for i in range(k):
            tasike.append(0)
        for i in range(len(self.user_graph_dict)):
            if len(self.user_graph_dict[i][0]) < k:
                count_num += 1
                if len(self.user_graph_dict[i][0]) == 0:
                    # pdb.set_trace()
                    user_graph_index.append(tasike)
                    continue
                user_graph_sample = self.user_graph_dict[i][0][:k]
                user_graph_weight = self.user_graph_dict[i][1][:k]
                while len(user_graph_sample) < k:
                    rand_index = np.random.randint(0, len(user_graph_sample))
                    user_graph_sample.append(user_graph_sample[rand_index])
                    user_graph_weight.append(user_graph_weight[rand_index])
                user_graph_index.append(user_graph_sample)

                user_weight_matrix[i] = F.softmax(torch.tensor(user_graph_weight), dim=0)  # softmax
                continue
            user_graph_sample = self.user_graph_dict[i][0][:k]
            user_graph_weight = self.user_graph_dict[i][1][:k]

            user_weight_matrix[i] = F.softmax(torch.tensor(user_graph_weight), dim=0)  # softmax
            user_graph_index.append(user_graph_sample)

        # pdb.set_trace()
        return user_graph_index, user_weight_matrix

    def print_embd(self):
        return self.result_embed_v, self.result_embed_t
    

    def adaptive_bpr_loss(self,
                      result_user_id: torch.Tensor,
                      result_user_t: torch.Tensor,
                      result_user_v: torch.Tensor,
                      user_nodes: torch.Tensor,
                      pos_item_nodes: torch.Tensor,
                      neg_item_nodes: torch.Tensor) -> torch.Tensor:
    
        def compute_gap(modal_emb: torch.Tensor):
            user_e = modal_emb[user_nodes]
            pos_e = modal_emb[pos_item_nodes]
            neg_e = modal_emb[neg_item_nodes]
            return torch.sum(user_e * pos_e, dim=-1) - torch.sum(user_e * neg_e, dim=-1)

        id_gap = compute_gap(result_user_id)
        txt_gap = compute_gap(result_user_t)
        vis_gap = compute_gap(result_user_v)

        gap_all = torch.stack([id_gap, txt_gap, vis_gap], dim=1)
        weights = 1.0 - F.softmax(gap_all, dim=1)
        weighted_gap = torch.sum(weights * gap_all, dim=1)

        bpr_score = torch.clamp(torch.sigmoid(weighted_gap), min=1e-8, max=1.0)
        loss = -torch.log(bpr_score).mean()

        return loss


    def lightgcn_user_propagate_sparse(self, user_emb: torch.Tensor,
                                    adj: torch.Tensor,
                                    n_layers: int = 2) -> torch.Tensor:
        """
        使用稀疏邻接矩阵进行 LightGCN 风格传播

        Args:
            user_emb: [num_user, dim] 初始用户 embedding（E^{(0)}）
            adj: 稀疏归一化邻接矩阵 [num_user, num_user] (coo)
            n_layers: 传播层数 K

        Return:
            final_emb: [num_user, dim] = 1/(K+1) * sum_{k=0}^K E^{(k)}
        """
        assert adj.is_sparse, "adj 必须是稀疏矩阵（sparse_coo_tensor）"

        all_layer_emb = [user_emb]
        x = user_emb

        for _ in range(n_layers):
            # 稀疏矩阵乘法： [num_user, num_user] @ [num_user, dim] -> [num_user, dim]
            x = torch.sparse.mm(adj, x)
            all_layer_emb.append(x)

        # layer-wise 平均
        final_emb = torch.stack(all_layer_emb, dim=0).mean(dim=0)

        return final_emb


    def build_user_sparse_adj(self, user_graph_dict: dict,
                            num_user: int,
                            device: torch.device = torch.device("cuda")) -> torch.Tensor:
        
        rows = []
        cols = []
        vals = []

        # 1) 收集原图边
        for u, (nbr_ids, nbr_ws) in user_graph_dict.items():
            # 防止是 numpy array，先转 list
            if not isinstance(nbr_ids, (list, tuple)):
                nbr_ids = list(nbr_ids)
            if not isinstance(nbr_ws, (list, tuple)):
                nbr_ws = list(nbr_ws)

            for v, w in zip(nbr_ids, nbr_ws):
                rows.append(u)
                cols.append(v)
                vals.append(float(w))

        # 2) 加 self-loop（权重=1）
        for u in range(num_user):
            rows.append(u)
            cols.append(u)
            vals.append(1.0)

        # 3) 转为 tensor
        rows = torch.tensor(rows, dtype=torch.long, device=device)
        cols = torch.tensor(cols, dtype=torch.long, device=device)
        vals = torch.tensor(vals, dtype=torch.float32, device=device)

        # 4) 计算度数 deg[i] = Σ_j A_ij
        deg = torch.zeros(num_user, dtype=torch.float32, device=device)
        deg = deg.index_add(0, rows, vals)   # 按行累加权重

        # 5) LightGCN 对称归一化 w_ij <- w_ij / sqrt(deg[i] * deg[j])
        deg_eps = deg + 1e-8
        norm_vals = vals / torch.sqrt(deg_eps[rows] * deg_eps[cols])

        # 6) 构造稀疏邻接矩阵
        indices = torch.stack([rows, cols], dim=0)   # [2, E]
        adj = torch.sparse_coo_tensor(indices, norm_vals,
                                    size=(num_user, num_user),
                                    device=device)
        adj = adj.coalesce()  # 合并重复边（如果有）

        return adj

    def path_based_bpr_loss_vectorized(self, user_ids, node_emb, adj,
                                   walk_len=4, num_walks=10, a=2):
        """
        user_ids: [B]  只包含用户节点的 index（0 ~ num_user-1）
        node_emb: [N, D] 所有节点的 embedding（user+item）
        adj:      torch.sparse_coo_tensor [N, N]，由 edge_index 构建
        walk_len, num_walks: 控制游走“深度”和次数
        a:        共现阈值
        """
        device = node_emb.device
        num_nodes = node_emb.size(0)
        batch_size = user_ids.size(0)

        # ------- 1. 初始化起点分布 [B, N] -------
        start_vec = torch.zeros((batch_size, num_nodes), device=device)
        start_vec[torch.arange(batch_size, device=device), user_ids] = 1.0

        # visit_counts[b, v] 表示 user b 对节点 v 的“访问次数/强度”
        visit_counts = torch.zeros_like(start_vec)

        x = start_vec
        steps = num_walks * walk_len
        for _ in range(steps):
            # x: [B, N] → [B, N]，稀疏矩阵乘
            # 注意 sparse.mm 的接口是 [N, N] @ [N, B]^T
            x = torch.sparse.mm(adj, x.T).T   # [B, N]
            visit_counts += x

        # 不把用户自己算进去
        visit_counts[torch.arange(batch_size, device=device), user_ids] = 0.0

        # ------- 2. 构建正负样本 mask -------
        pos_mask = (visit_counts >= a).float()                  # [B, N]
        neg_mask = ((visit_counts > 0) & (visit_counts < a)).float()

        # 有些用户可能没有满足条件的正/负样本，先筛掉
        valid_mask = (pos_mask.sum(dim=1) > 0) & (neg_mask.sum(dim=1) > 0)
        if valid_mask.sum() == 0:
            return torch.tensor(0.0, device=device)

        user_ids = user_ids[valid_mask]
        pos_mask = pos_mask[valid_mask]
        neg_mask = neg_mask[valid_mask]

        pos_den = pos_mask.sum(dim=1, keepdim=True).clamp(min=1)
        neg_den = neg_mask.sum(dim=1, keepdim=True).clamp(min=1)

        # ------- 3. 计算“虚拟正负样本中心” -------
        # [B, N] @ [N, D] = [B, D]
        pos_center = (pos_mask @ node_emb) / pos_den
        neg_center = (neg_mask @ node_emb) / neg_den
        user_vecs = node_emb[user_ids]  # [B, D]

        # ------- 4. BPR Loss -------
        pos_score = (user_vecs * pos_center).sum(dim=1)
        neg_score = (user_vecs * neg_center).sum(dim=1)
        loss = -torch.log(torch.sigmoid(pos_score - neg_score))
        return loss.mean()






    def build_torch_sparse_adj(self, edge_index, num_nodes, device):
        """
        edge_index: torch.LongTensor [2, num_edges]
        num_nodes:  int，总节点数（用户+物品）
        device:     torch.device
        """
        # 保证在指定 device 上
        edge_index = edge_index.to(device)

        # 每条边的权重都置为 1（如果你之后要做加权可以改这里）
        values = torch.ones(edge_index.size(1), device=device)

        # 构造稀疏邻接矩阵
        adj = torch.sparse_coo_tensor(
            edge_index, values, size=(num_nodes, num_nodes)
        ).coalesce()

        return adj










class GCN(torch.nn.Module):
    def __init__(self, datasets, batch_size, num_user, num_item, dim_id, aggr_mode,
                 dim_latent=None, device=None, features=None):
        super(GCN, self).__init__()
        self.batch_size = batch_size
        self.num_user = num_user
        self.num_item = num_item
        self.datasets = datasets
        self.dim_id = dim_id
        self.dim_feat = features.size(1)
        self.dim_latent = dim_latent
        self.aggr_mode = aggr_mode
        self.device = device

        if self.dim_latent:
            self.preference = nn.Parameter(nn.init.xavier_normal_(torch.tensor(
                np.random.randn(num_user, self.dim_latent), dtype=torch.float32, requires_grad=True),
                gain=1).to(self.device))
            self.MLP = nn.Linear(self.dim_feat, 4 * self.dim_latent)
            self.MLP_1 = nn.Linear(4 * self.dim_latent, self.dim_latent)
            self.conv_embed_1 = Base_gcn(self.dim_latent, self.dim_latent, aggr=self.aggr_mode)

        else:
            self.preference = nn.Parameter(nn.init.xavier_normal_(torch.tensor(
                np.random.randn(num_user, self.dim_feat), dtype=torch.float32, requires_grad=True),
                gain=1).to(self.device))
            self.conv_embed_1 = Base_gcn(self.dim_latent, self.dim_latent, aggr=self.aggr_mode)

    def forward(self, edge_index_drop, edge_index, features, perturbed=False):
        temp_features = self.MLP_1(F.leaky_relu(self.MLP(features))) if self.dim_latent else features
        x = torch.cat((self.preference, temp_features), dim=0).to(self.device)
        x = F.normalize(x).to(self.device)

        h = self.conv_embed_1(x, edge_index)
        if perturbed:
            random_noise = torch.rand_like(h).cuda()
            h += torch.sign(h) * F.normalize(random_noise, dim=-1) * 0.1
        h_1 = self.conv_embed_1(h, edge_index)
        if perturbed:
            random_noise = torch.rand_like(h).cuda()
            h_1 += torch.sign(h_1) * F.normalize(random_noise, dim=-1) * 0.1
        # h_2 = self.conv_embed_1(h_1, edge_index)

        x_hat = x + h + h_1
        return x_hat, self.preference


class Base_gcn(MessagePassing):
    def __init__(self, in_channels, out_channels, normalize=True, bias=True, aggr='add', **kwargs):
        super(Base_gcn, self).__init__(aggr=aggr, **kwargs)
        self.aggr = aggr
        self.in_channels = in_channels
        self.out_channels = out_channels

    def forward(self, x, edge_index, size=None):
        # pdb.set_trace()
        if size is None:
            edge_index, _ = remove_self_loops(edge_index)
            # edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))
        x = x.unsqueeze(-1) if x.dim() == 1 else x
        # pdb.set_trace()
        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)

    def message(self, x_j, edge_index, size):
        if self.aggr == 'add':
            # pdb.set_trace()
            row, col = edge_index
            deg = degree(row, size[0], dtype=x_j.dtype)
            deg_inv_sqrt = deg.pow(-0.5)
            norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]
            return norm.view(-1, 1) * x_j
        return x_j

    def update(self, aggr_out):
        return aggr_out

    def __repr(self):
        return '{}({},{})'.format(self.__class__.__name__, self.in_channels, self.out_channels)

class Align_MoE(nn.Module):
    def __init__(self, config):
        super(Align_MoE, self).__init__()

        self.expert_num = config["start_expert_num"]
        self.hidden_size = 64
        self.gate_selection = config["start_gate_selection"]

        self.gate_txt = nn.Linear(self.hidden_size, self.expert_num)
        self.gate_img = nn.Linear(self.hidden_size, self.expert_num)
        self.gate_id  = nn.Linear(self.hidden_size, self.expert_num)

        self.expert = nn.ModuleList([
            nn.Linear(self.hidden_size * 3, self.hidden_size * 3)
            for _ in range(self.expert_num)
        ])

        # 三模态融合的“原始参数”，还没 softmax
        init_w = torch.tensor(config["initializer_weight"], dtype=torch.float32)
        self.weight_raw = nn.Parameter(init_w)  # shape=[3]

    def forward(self, vector):
        # ---- 维度处理 ----
        if vector.dim() == 2:
            vector = vector.unsqueeze(1)   # [N, 1, D]
        B, N, D = vector.shape             # D = hidden_size * 3

        # ---- 多专家前向 ----
        expert_output = []
        for i in range(self.expert_num):
            out_i = self.expert[i](vector)          # [B, N, D]
            expert_output.append(out_i.unsqueeze(2))  # [B, N, 1, D]
        expert_output = torch.cat(expert_output, dim=2)  # [B, N, expert_num, D]

        # ---- 切分三模态 ----
        id_part  = expert_output[:, :, :, :self.hidden_size]
        txt_part = expert_output[:, :, :, self.hidden_size:2*self.hidden_size]
        img_part = expert_output[:, :, :, 2*self.hidden_size:]

        # ---- 三个 gate ----
        gate_id_score = F.softmax(self.gate_id(vector[:, :, :self.hidden_size]), dim=-1)
        gate_txt_score = F.softmax(self.gate_txt(vector[:, :, self.hidden_size:2*self.hidden_size]), dim=-1)
        gate_img_score = F.softmax(self.gate_img(vector[:, :, 2*self.hidden_size:]), dim=-1)

        gate_id_score  = gate_id_score.unsqueeze(3)    # [B, N, expert_num, 1]
        gate_txt_score = gate_txt_score.unsqueeze(3)
        gate_img_score = gate_img_score.unsqueeze(3)

        # ---- 对原始 weight 做 softmax，但不要覆盖属性 ----
        weight = F.softmax(self.weight_raw, dim=0)     # [3]

        id_out  = weight[0] * torch.sum(id_part  * gate_id_score,  dim=2)  # [B, N, hidden]
        txt_out = weight[1] * torch.sum(txt_part * gate_txt_score, dim=2)
        img_out = weight[2] * torch.sum(img_part * gate_img_score, dim=2)

        # ---- 如果输入原本是 2D，则 squeeze 回去 ----
        if id_out.shape[1] == 1:
            id_out  = id_out.squeeze(1)
            txt_out = txt_out.squeeze(1)
            img_out = img_out.squeeze(1)

        return [id_out, txt_out, img_out]




